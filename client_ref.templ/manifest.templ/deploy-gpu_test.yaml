apiVersion: apps/v1
kind: Deployment
metadata:
  name: gpu-test
  namespace: sample
spec:
  replicas: 1
  selector:
    matchLabels:
      app: gpu-test
  template:
    metadata:
      labels:
        app: gpu-test
    spec:
      containers:
      - name: gpu-test-ct
        image: nvcr.io/nvidia/cuda:12.4.1-base-ubuntu22.04
        command: ["/bin/bash"]
        args:
        - "-c"
        - |
          apt-get update && \
          DEBIAN_FRONTEND=noninteractive apt-get install -y python3-pip nvidia-utils-535 lsb-release && \
          pip3 install torch torchvision torchaudio
          
          echo "Running initial GPU test..."
          python3 -c "
          import torch
          print('CUDA available:', torch.cuda.is_available())
          print('CUDA device count:', torch.cuda.device_count())
          if torch.cuda.is_available():
              print('CUDA device name:', torch.cuda.get_device_name(0))
              x = torch.rand(5, 3)
              print('Tensor on CPU:', x)
              x = x.cuda()
              print('Tensor on GPU:', x)
          "
          
          echo "Initial test complete. Container will now sleep to allow for further testing via exec."
          
          # Keep the container running
          while true; do sleep 3600; done
        resources:
          limits:
            nvidia.com/gpu: 1